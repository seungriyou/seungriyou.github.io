---
title: "[Week 06] 멘토링"
date: 2022-02-25 23:50:00 +0900
categories: [부스트캠프 AI Tech 3기, Mentoring]
tags: [부스트캠프AITech, mentoring, week06, lv1-p-stage, competitions]     # TAG names should always be lowercase
image: 
  path: /assets/img/posts/Boostcamp-AI-Tech/boostcamp_ai_tech_title.png
math: true
---

> 대회 관련 조언

## **Model**

- “어느정도 데이터는 어느정도 복잡도의 모델이 좋겠구나” 하는 감을 익혀야 한다.
    - 쉬운 데이터는 alexnet이 좋을 수도,
    - 복잡한 데이터는 resnet이 좋을 수도,
        - CIFAR 데이터에는 resnet18이 resnet34보다 좋다.
    - 더 복잡한 이미지 데이터는 다른 모델이 좋을 수도 있다!
    > 경험을 하자!
- 모델을 바꿔보다가 이 정도 depth가 괜찮다는 걸 알면 그 정도 depth/복잡도의 최신 모델을 적용해보자.
    - resnet18이 잘 됐다면 resnext 등 비슷한 계열의 모델을 시도해본다.
- 모델 한 명당 하나씩 맡아서 report 해주면 좋을 것 같다.
- ViT pretrained 가져와서 fine-tuning 하면 결과가 좋을 것 같다.
    - 생각해 볼 점) 과연 우리의 데이터가 imagenet 데이터와 유사한가?

<br>

## **Augmentation**

- cutmix
    - label이 바뀌어서 loss 함수도 바뀌기 때문에 jupyter notebook 환경으로 실행하려면 번거롭다.
- 알맞은 augmentation도 데이터의 종류마다 다르다.
    - 웬만하면 random crop은 좋지만, 우리 대회에서는 마스크가 crop되면 안된다!
        - random crop의 크기를 크게 해보자!
    - 색감, 밝기 조절, 반전, 회전 등을 한 사람씩 맡아서 해보자!
    - 좋은거 다 하면 당연히 좋다! 정답은 없고, 안 좋은건 안 넣고 좋은건 넣으면 된다.
    - 하다보면 감이 익혀진다. 대회 높은 등수보다도... 이것을 목표로!

<br>

## **Batch size와 Learning rate의 관계**
> ex) batch size가 원래 모델에서 128였는데, 지금은 img 줄여서 64로 하는 상황  
> ⇒ 이럴 때 learning rate는? 

- 논문 1 - [https://arxiv.org/abs/1710.06451](https://arxiv.org/abs/1710.06451)
    - noise scale = SGD와 같이 mini-batch 사용 시 발생하는 noise
    - $B$ = `batch_size`, $\epsilon$ = `lr`
    - **`batch_size`와 `lr`을 같은 배수로 비례하게 줄이는 것이 좋다!**
- 논문 2 - [https://arxiv.org/abs/1706.02677](https://arxiv.org/abs/1706.02677)
    - **linear scaling rule** - minibatch size $k$배 하면 learning rate도 $k$배 해야 한다.
    - 하지만 batch size를 너무 줄이면 안된다!
        - batchnorm 사용하는 경우 → 어느정도 크기가 유지되어야지 평균, 분산이 잘 유지될 수 있다.
        - **batchsize는 적어도 16, 32 이상**으로 linear scaling rule을 따라서 하자.
    - 논문을 근거로 들어서 시도해보자. (누군가는 증명했다)
    - 실험을 통해서 입증해보는 것도 좋을 것 같다.

<br>

## **기타**

- baseline 코드의 line by line으로 주석을 달아보면서 이해하자.
- grad cam 쓰려면 resnet보다 vgg처럼 간단한 모델을 쓰는 편이 좋을 수 있다!
    - grad cam이 실제로 볼 곳을 어느정도 예측해준다는 느낌
    - 모델이 실제로 여기에 주목한다는 것보다는 조금 더 설득력있게 사용하는 느낌으로
- weakly-supervised learning
    - network가 집중하는 영역에 box를 치면 detection이 될 것이다.