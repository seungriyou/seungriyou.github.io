---
title: "[Week 05] 멘토링"
date: 2022-02-16 23:50:00 +0900
categories: [부스트캠프 AI Tech 3기, Mentoring]
tags: [부스트캠프AITech, mentoring, week05, VAE, GAN, ELBO, transformer, SSD, Faster-R-CNN, paper]     # TAG names should always be lowercase
image: 
  path: /assets/img/posts/Boostcamp-AI-Tech/boostcamp_ai_tech_title.png
math: true
---

## **수업 관련 내용**
### **ELBO 식을 어떻게 이해해야 할까?**
- **GAN** = decoder
    - 대신 discriminator 추가
- **VAE** = GAN(decoder) + encoder
    - 최적화 하기 위하여 KL divergence를 최소화해야 하지만, 이를 구할 수 없다.
    - 따라서 ELBO를 최대화하는 방법을 이용한다.
        - **reconstruction term** - encoder → decoder 하면 자기 자신이 나와야 한다.
        - **prior fitting term** - latent space를 isotropic Gaussian 분포를 따른다고 가정한다.

> - **GAN** - 훈련 과정 불안정 (discriminator, penalty..)
> - **VAE** - 훈련 과정 불안정하지는 않으나, 계산을 위해서 latent space가 정규분포를 따른다고 가정할 수밖에 없다.  
>   ⇒ 따라서 현실적으로는 <span style='background-color: #fff5b1'>GAN이 더 성능이 좋은 경향</span>이 있다. (VAE의 output이 더 흐린 편이다.)
{: .prompt-note}

### **transformer의 decoder의 입력은?**
- encoder는 decoder에게 query 값으로 input을 넣어준다.
    - 즉, 생성을 하는 데에 encoder가 도움을 준다. (원래 decoder만으로도 생성은 가능하다.)
- 사용 예시
    - encoder만으로도 할 수 있는 것 → 감정 예측
        
        > 또한, **ViT**는 **분류 모델**이므로 encoder로 충분하다.
        > 
    - decoder만으로도 할 수 있는 것 → 문장 생성
    - encoder + decoder로 할 수 있는 것 → 언어 번역

### **positional encoding**
- 처음에는 `sin` & `cos` 조합한 것으로 사용했다.
- 요즘에는 trainable하게 준다.
    - ViT 실습에서도 `Parameter`로 줬다. (image embedding에서 `self.positions`)

<br>

## **논문 스터디 (SSD & Faster R-CNN)**
### **SSD**
- 1 stage (하나의 regression 문제로)

### **Faster R-CNN**
- 2 stage (찾기 + 분류)

- **4단계의 training 과정**
    - feature map에서 자르는 이유
        - RPN과 R-CNN이 network를 공유하게 된다.
        - 이러한 구조가 2 stage model의 표준이 되었다.
    - 학습 과정을 나눈 이유
        - 미분 불가능한 지점이 있어 학습이 한 번에 불가능 하기 때문이다.
        - 최근에는 그냥 joint training으로 한다. (미분 안되어도 큰 지장 없어서 괜찮다.)
        - 이제는 4단계로 할 필요가 없다.
- **loss function에서 한 term 자체를 없애면 loss들 간 scale 자체가 달라지는 문제가 발생할 수 있지 않나?**
    - box 수에 비례하게 loss를 구한다고 생각하면 뜻이 더 통한다.
    - 대부분의 경우, `negative(배경)`의 비율이 `positive(물체)`의 비율에 비해 높다.
        - `negative(배경)`는 인식해야 하는 물체가 아님에도 불구하고 훈련이 더 진행되는 경향이 있다.
        - `negative` : `positive` = `100` : `1`이라면, `negative` 100개 예측이 `positive` 1개 예측보다 쉬울 수 있는 것이다.
- **그 외에 생각해 볼 것**
    - regression 시 log scale로 하는 것이 좋은가?
    - anchor box는 어떻게 구하는가?
    - training 과정은 어떻게 이뤄지는가?
    - **NMS** (Non-Maximum Suppression)
        - 예측한 bounding box가 여러 개이면 가장 좋은 것만 남긴다.
        - 안하면 인식 대상인 물체가 하나여도 bb는 수십 개가 나올 수도 있다.

    > Faster R-CNN 구조는 완벽히 이해하는 것을 추천한다.
    {: .prompt-warning}

### **1 stage와 2 stage의 차이점**
- **1 stage** (ex. SSD)
    - 실시간성
    - input size에 민감하다. (ex. SSD의 경우, training data의 size대로 300, 512 등 맞춰주어야 한다.)
- **2 stage** (ex. Faster R-CNN)
    - 정확도
    - input size가 딱히 정해지지 않았다. (2048 짜리도 들어갈 수 있다.)
    - 2 stage model이 느리다고 알려진 이유도 1 stage model과 input image size 자체가 다르기 때문이기도 하다.

> 상황에 맞춰서 사용하자!