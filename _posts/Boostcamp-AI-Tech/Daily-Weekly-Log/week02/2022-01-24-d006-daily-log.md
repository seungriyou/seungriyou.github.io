---
title: "[Week 02 / Day 006] 학습 기록"
date: 2022-01-24 23:03:00 +0900
categories: [부스트캠프 AI Tech 3기, Daily & Weekly Log]
tags: [부스트캠프AITech, daily-log, week02, lv1-u-stage]     # TAG names should always be lowercase
math: true
image: 
  path: /assets/img/posts/Boostcamp-AI-Tech/boostcamp_ai_tech_title.png
---
## **📝 오늘 한 일**
- 데일리 스크럼
- 강의 수강 및 정리
    - [PyTorch 1강]
    - [PyTorch 2강]
    - [PyTorch 3강]
- 퀴즈 풀기
- 기본 과제 1 (하는 중)
- 피어세션
- 알고리즘 스터디 문제 풀이

<br>

## **👥 피어세션 요약**
오늘 피어세션에서는 개인별 진도를 확인하고, 강의 및 과제에서 궁금한 점에 대해 이야기를 나누고, week01 과제의 코드 리뷰를 진행하였다. 우선, `view`와 `reshape`의 차이인 contiguity에 대해서 가장 이야기 할 점이 많았다. 강의에서는 `view`를 사용하라고 하셨지만, 실제로는 `view`를 쓰다보면 에러가 자주 발생하여 `reshape`을 더 자주 사용한다는 팀원분들이 계셨다. 따라서 교수님께서 `view`를 사용하라고 하신 것은 `reshape` 시에는 몇몇 경우에 copy가 발생하여 메모리 측면에서 손해가 발생할 수도 있기 때문일 것이라고 추측하였다. 또한, 나는 PyTorch 2강 강의에서 벡터로 이루어진 식의 `backward` 함수에는 `gradient`를 왜 명시적으로 파라미터로 넣어주는지, 그리고 왜 그 tensor의 값은 `[1., 1.]`인지 궁금했었는데, 우선은 computational graph에서 backprop을 진행할 때 처음 input으로 1을 넣어주는 것이 관련이 있지 않을까라고 결론을 지었다.
```python
a = torch.tensor([2., 3.], requires_grad=True
b = torch.tensor([6., 4.], requires_grad=True
Q = 3*a**3 - b**2
external_grad = torch.tensor([1., 1.])
Q.backward(gradient=external_grad)

a.grad    # tensor([36., 81.])
b.grad    # tensor([-12.,  -8.])
```

> 💡 [PyTorch 튜토리얼](https://tutorials.pytorch.kr/beginner/blitz/autograd_tutorial.html) \
> ⇒ `Q` 는 벡터(vector)이므로 `Q.backward()` 에 `gradient` 인자(argument)를 명시적으로 전달해야 합니다. `gradient` 는 `Q` 와 같은 모양(shape)의 텐서로, `Q` 자기 자신에 대한 변화도(gradient)를 나타냅니다. 즉 $\frac{dQ}{dQ} = 1$입니다.

또한, 지난주 과제에 대해 코드리뷰를 진행하였다. 더 깔끔한 파이썬 코드를 위한 방법으로 리스트 컴프리헨션, 삼항 연산자, IDE로 파이참 사용하기 등이 있었다.

<br>

## **📚 과제 내용 정리**
기본 과제 1을 아직 푸는 중이다.

<br>

## **🐾 일일 회고**
이번주는 PyTorch를 배운다. 학교 수업시간에는 (아주 잠깐) TensorFlow만 써봤었고, PyTorch는 조금 따라해 본 정도로 밖에 경험이 없는데, 이번 기회에 많이 익숙해졌으면 좋겠다. 그리고 지난주와 다르게 이번에는 강의 분량이 적절한 것 같아 다행이다. (덕분에 실습을 따라 해보는 데에 더 많이 투자할 수 있었다.) 비록 오늘은 팀 깃허브에 알고리즘 스터디 저장소를 만든다고 시간을 쏟느라 피어세션 전까지 계획된 분량을 다 하지는 못했지만... 😥 또한, 이번주는 내가 모더레이터를 맡았다. 나는 이런 역할을 맡을 때마다 내 자신이 너무 부족하게 느껴진다. 그래도 최선을 다해야겠다!

<br>

## **🚀 내일 할 일**
- 강의 수강 & 정리
    - [PyTorch 4강]
    - [PyTorch 5강]
- 퀴즈 풀기
- 기본 과제 1 마무리
- 기본 과제 2
- 알고리즘 스터디 문제 풀이
- git blog 정비하기