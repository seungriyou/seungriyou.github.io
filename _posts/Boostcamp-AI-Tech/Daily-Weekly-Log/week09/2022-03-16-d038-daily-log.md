---
title: "[Week 09 / Day 038] 학습 기록"
date: 2022-03-16 22:50:00 +0900
categories: [부스트캠프 AI Tech 3기, Daily & Weekly Log]
tags: [부스트캠프AITech, daily-log, week09, lv2-u-stage, cgan, clip, assignment]     # TAG names should always be lowercase
image: 
  path: /assets/img/posts/Boostcamp-AI-Tech/boostcamp_ai_tech_title.png
math: true
---
## **📝 오늘 한 일**
- [x]  기본 과제 4, 5
- [x]  퀴즈

<br>

## **👥 피어세션 요약**
최종 프로젝트 주제에 대해서 이야기를 나누었다. 데드라인을 정해놓고 노션에서 브레인스토밍을 해 볼 예정이다!

<br>

## **📚 과제 내용 정리**
### **기본 과제 4** -  cGAN (Conditional GAN)
- **스켈레톤 코드 분석 (`batch_size=64` 가정)**
    - `real_imgs` ($x$) = [64, 1, 28, 28]
        - MNIST 데이터셋이므로 1×28×28이다.
    - `labels` / `gen_labels` ($y$) = [64, 10]
        - 스켈레톤 코드에서 이미 one-hot vector들의 tensor로 만들어놓았다.
        - 다른 코드들에서는 [64]로만 들어가서, 모듈 내부에서 embedding 된다.
    - `noise` ($z$) = [64, 100]
- **겪었던 문제 상황**
    - **임베딩 (embedding)**
        - 무엇인지 모르겠어서 여러 코드를 찾아보았으나, 인터넷에 올라와 있는 cGAN 구현 코드와 과제의 스켈레톤 코드가 달라 한참을 헤맸다.
        - 구현되어 있는 코드 대부분은 `nn.Embedding`을 이용해서 1차원 tensor `label`을 임베딩하는데, 스켈레톤 코드에서는 이미 `labels`, `gen_labels`가 2차원 tensor(**one-hot vector**)로 주어진다. 따라서 또 `nn.Embedding`을 적용하면 안됐다.
        - 결국, 과제의 설명을 따르는 것이 정답이었다. 과제의 설명에 따르면 <span style="background-color: Lavenderblush">**임베딩 == nn.Linear에 넣기**</span>이며, 그 결과를 그대로 concat 하여 사용하면 되는 것이었다. 따라서 `nn.Linear`의 두 번째 차원을 1/2씩 줄여서 넣어야 했다.
    - **수많은 런타임 에러 😱**
        - 너무나도 한심한 실수들 때문에 벌어진 일이라 설명은 생략한다...
    - **activation function**
        - 과제 설명에 충실하여 코드를 짰으나 generator loss가 폭발하고 discriminator loss가 수렴하는 문제가 발생했다. 검색해보니 이 정도는 아키텍처가 잘못된 것이라고 해서, 다른 구현된 코드들을 참고해봤다.
            
        ![](/assets/img/posts/Boostcamp-AI-Tech/Daily-Log/week09/d038-1.png){: width="60%" height="60%"}
            
        - 우선, `nn.ReLU()`를 `nn.LeakyReLU(0.2, inplace=True)`로 바꿔보았다. 그래도 딱히 나아지지 않았다.

        - generator의 마지막 activation function인 `nn.Sigmoid()`를  `nn.Tanh()`로 바꿔보았다. 그랬더니 바로 적절한 generator loss 값과 discriminator loss 값이 관찰되었다.
            
            > generator loss와 discriminator loss가 수렴하지 않는 것처럼 보이는 현상은 자연스러운 현상이다.
            {: .prompt-warning}
            
            ![](/assets/img/posts/Boostcamp-AI-Tech/Daily-Log/week09/d038-2.png){: width="65%" height="65%"}
            
- **결과 (epoch 50)** - 깔끔하게 잘 나온다!!!
    
    ![](/assets/img/posts/Boostcamp-AI-Tech/Daily-Log/week09/d038-3.png){: width="70%" height="70%"}

<br>

### **기본 과제 5** - CLIP 모델을 통한 Multi-modal 모델의 다양한 활용
- **기억할 것**
    - `torch.topk` - 예측 값에서 argmax가 아닌 top-k 개의 결과 값을 얻을 때 사용한다.
        
        ```python
# softmax 함수로 가장 높은 K개의 확률값 구하기
K = 10    
values, indices = torch.topk(similarity.softmax(dim=-1), k=K, dim=-1)
        ```
        
- **과제 내용 일부** 
  
    > 너무 신기해서 사진을 꼭 넣고 싶었다

    - **텍스트와 이미지가 일치할 확률**
        
        ![](/assets/img/posts/Boostcamp-AI-Tech/Daily-Log/week09/d038-4.png){: width="40%" height="40%"}
        
        ![](/assets/img/posts/Boostcamp-AI-Tech/Daily-Log/week09/d038-5.png){: width="70%" height="70%"}
        
    - **zero-shot image classification**
        
        ![](/assets/img/posts/Boostcamp-AI-Tech/Daily-Log/week09/d038-6.png){: width="35%" height="35%"}
        
    - **“a white yacht on the emerald sea” 라는 텍스트에 의해 생성된 이미지**
        
        ![](/assets/img/posts/Boostcamp-AI-Tech/Daily-Log/week09/d038-7.png){: width="20%" height="20%"}

<br>

## **🐾 일일 회고**
오늘은 하루 종일 과제만 하느라 하나 남은 강의를 마저 듣지도 못했고 다른 할 일도 못했다... 하지만 수많은 삽질과 런타임 에러 끝에 과제를 완성해냈다는 점만으로도 뿌듯하게 생각하려 한다. 특히 CLIP은 좋다고 들어보기만 했었는데, 실제로 사용해보니까 너무 너무 재미있어서 과제 중에 힐링 타임을 가진 듯한 느낌이었다. 심화 과제는 아직 다 풀지 못했는데 내일 답지가 올라오기 전까지는 끝까지 봐야겠다.

<br>

## **🚀 내일 할 일**
- [ ]  강의 수강 및 정리
    - [CV] 10강
- [ ]  알고리즘
- [ ]  삶의 지도 Notion에 옮기기
- [ ]  심화 과제 2, 3