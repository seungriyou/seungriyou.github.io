---
title: "[Week 04 / Day 016] 학습 기록"
date: 2022-02-10 22:40:00 +0900
categories: [부스트캠프 AI Tech 3기, Daily & Weekly Log]
tags: [부스트캠프AITech, daily-log, week04, lv1-u-stage]     # TAG names should always be lowercase
image: 
  path: /assets/img/posts/Boostcamp-AI-Tech/boostcamp_ai_tech_title.png
math: true
---
## **📝 오늘 한 일**
- [x] 강의 수강 및 정리
    - [Data Viz] 5-1, 2, 3강
- [x] 기본 과제 1, 2, 3, 4, 5 제출
- [x] 오피스아워

<br>

## **👥 피어세션 요약**
### **키워드 공유**
- GAN의 종류
- KL divergence가 metric으로서 적합하지 않은 이유는?
    - 역으로 성립이 안하기 때문이다.
    - JS divergence는 역으로 성립이 가능하기 때문에 metric으로서 적합하다고 한다.
        - 하지만 이것도 VAE에서는 웬만큼 되는데 GAN에서는 잘 안된다.
    - Wasserstein distance를 사용한다. (Earth Move Distance or Loss)
- JS 부등식
- AE와 VAE의 차이점
    - **AE** - manifold learning (고차원에서 어떠한 관계가 있을 것이라고 가정)
    - **VAE** - generative model
    
    > “[오토인코더의 모든 것](https://www.youtube.com/watch?v=o_peo6U7IRM)"이라는 강의에서 잘 다룬다.
    > 
- PixelCNN, Row LSTM, Diagonal BiLSTM의 차이점
    - **Row LSTM** - 이전 픽셀들을 모두 사용하면 속도가 매우 느려지기 때문에, receptive field를 삼각형 모양을 가지도록 구성한다.
    - **Diagonal BiLSTM** - 모든 픽셀을 반영하므로 Row LSTM에 비해 속도는 느리지만 정확도는 더 높다.

### **질문**
- categorical distribution의 parameter 개수
    - one-hot encoding

<br>

## **📚 오피스아워 정리**
ViT와 AAE 논문을 구현하는 심화과제의 해설을 들었다. 어렵더라도 한 줄 한 줄 꼭 소화해야 한다.

<br>

## **🐾 일일 회고**
오늘은 이번주에 할당된 강의를 모두 들었고, 기본 과제도 모두 제출했다. 그리고 심화 과제를 아직 다 풀어보지 못한 상태에서 오피스아워에 참여했는데, 조교님께서 이론적인 부분부터 이해하기 쉽게 설명해주셔서 도움이 많이 되었다. 특히 논문 구현은 대학원생들도 어려워하는 것이라며 한 줄 한 줄 꼼꼼하게 이해하고 써보길 추천해주셨다. 빠른 시일 내에 꼭 직접 해보자..!

<br>

## **🚀 내일 할 일**
- [ ] 학습 정리 제출
- [ ] 맥북 환경 구축
- [ ] 주간 회고
- [ ] 스페셜 피어세션
- [ ] 마스터클래스
- [ ] 부족한 정리 마무리