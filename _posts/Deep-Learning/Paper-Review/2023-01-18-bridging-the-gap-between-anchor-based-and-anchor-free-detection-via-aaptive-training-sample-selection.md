---
title: "[Paper] Bridging the Gap Between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection"
date: 2023-01-18 19:50:00 +0900
categories: [Deep Learning, Paper Review]
tags: [paper review, object detection, atss, retinanet, fcos]
math: true
---

> ğŸ“ Paper: <https://arxiv.org/abs/1912.02424>

<br>

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” **one-stage <span style="color: MediumVioletRed">anchor-based</span> detector(ex. RetinaNet**)ì™€ **center-based <span style="color: RoyalBlue">anchor-free</span> detector(ex. FCOS**)ì˜ ë³¸ì§ˆì ì¸ ì°¨ì´ëŠ” <span class="hl">positiveì™€ negative training samplesë¥¼ ì •ì˜í•˜ëŠ” ë°©ë²•</span>ì´ë¼ê³  ë§í•˜ê³  ìˆë‹¤.

ë˜í•œ, <span class="hl">positive sampleê³¼ negative sampleì„ ì •ì˜í•˜ëŠ” ìƒˆë¡œìš´ ë°©ë²•</span>ì¸ **ATSS**ë¥¼ ì†Œê°œí•˜ì—¬, ì´ë¥¼ í†µí•´ anchor-based ë°©ë²•ê³¼ anchor-free ë°©ë²• ê°„ì˜ ì°¨ì´ë¥¼ ì¤„ì¼ ìˆ˜ ìˆë‹¤ê³  ì£¼ì¥í•œë‹¤.

<br>

## 1. Abstract

object detectionì€ **anchor-based detectors**ì— ì˜í•´ ì£¼ë„ë˜ì–´ ì™”ìœ¼ë‚˜, ìµœê·¼ì—ëŠ” FPNê³¼ focal lossì˜ ë“±ì¥ìœ¼ë¡œ **anchor-free detectors**ë„ ì£¼ëª©ë°›ê³  ìˆë‹¤.

1. **anchor-basedì™€ anchor-freeì˜ ê°€ì¥ ì¤‘ìš”í•œ ì°¨ì´ì **ì´ <span class="hl">**â€œpositive / negative training samplesë¥¼ ì •ì˜í•˜ëŠ” ë°©ë²•â€**</span>ì´ë¼ê³  ì–¸ê¸‰í•œë‹¤. 

    ì¦‰, positive / negative samplesë¥¼ ê°™ê²Œ ì •ì˜í•œë‹¤ë©´, **boxë¥¼ regression(= <span style="color: MediumVioletRed">anchor-based</span>)**í•˜ë“  **pointë¥¼ regression(= <span style="color: RoyalBlue">anchor-free</span>)**í•˜ë“ ì§€ê°„ì— ìµœì¢… ì„±ëŠ¥ì—ëŠ” ì°¨ì´ê°€ ì—†ë‹¤.

    > ğŸ“Œ **Positive Sample vs. Negative Sample**
    >
    > | --- | --- |
    > | **positive sample** | ê°ì²´ ì˜ì—­ |
    > | **negative sample** | ë°°ê²½ ì˜ì—­ |
    
2. **Adaptive Training Sample Selection(ATSS)**ì„ ì œì•ˆí•œë‹¤.
    - objectì˜ í†µê³„ì  íŠ¹ì„±ì„ ì´ìš©í•˜ì—¬ positive / negative samplesë¥¼ ìë™ìœ¼ë¡œ ì„ íƒí•˜ëŠ” ë°©ë²•ì´ë‹¤.
    - anchor-basedì™€ anchor-freeì˜ performanceë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚¤ë©°, ê·¸ ë‘˜ ì‚¬ì´ì˜ ì„±ëŠ¥ ì°¨ì´ë¥¼ ì¤„ì—¬ì¤€ë‹¤.
    - overhead ì—†ì´ SOTA detectorsì˜ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆë‹¤. (50.7% AP)
3. ì´ë¯¸ì§€ì˜ ê° location ë§ˆë‹¤ **ì—¬ëŸ¬ anchorsë¥¼ tiling í•˜ëŠ” ê²ƒì€ ë¶ˆí•„ìš”**í•˜ë‹¤.

<br>

---

## 2. Introduction & Related Work

### 2.1 <span style="color: MediumVioletRed">Anchor-based</span> Detector

> dominate, SOTAì˜ ëŒ€ë‹¤ìˆ˜ë¥¼ ì°¨ì§€í•œë‹¤.

- **one-stage methods (ex. SSD)**
    - ê³„ì‚°ì˜ íš¨ìœ¨ì„± â†’ ë¹ ë¥´ë‹¤.
- **two-stage methods (ex. Faster R-CNN)**
    - ë³´ë‹¤ ì •í™•í•œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë„ì¶œí•œë‹¤.
- **ê³µí†µì **
    - ê° ì´ë¯¸ì§€ë§ˆë‹¤ ë§ì€ ìˆ˜ì˜ preset anchorsë¥¼ tiling í•œë‹¤.
    - ì´ëŸ¬í•œ anchorsì˜ ì¹´í…Œê³ ë¦¬ë¥¼ ì˜ˆì¸¡í•˜ê³  ì¢Œí‘œë¥¼ ì •ì œí•œë‹¤.
    - ì •ì œí•œ anchorsë¥¼ detection ê²°ê³¼ë¡œ ë„ì¶œí•œë‹¤.

<br>

### 2.2 <span style="color: RoyalBlue">Anchor-free</span> Detector

> FPNê³¼ Focal Lossì˜ ë“±ì¥ìœ¼ë¡œ ì£¼ëª© ë°›ê³  ìˆë‹¤.

- preset anchors ì—†ì´ ë°”ë¡œ objectë¥¼ ì°¾ëŠ”ë‹¤.
- **keypoint-based methods**
    - ë™ì‘
        1. locate several pre-defined or self-learned keypoints
        2. bound the spatial extent of objects
    - pose estimation ë¶„ì•¼ì—ì„œ ì£¼ë¡œ ë§ì´ ì“°ì´ëŠ” ë°©ë²•ì´ë‹¤.
    - ex) CornerNet(top-left, bottom-right), ExtremeNet(top-most, left-most, bottom-most, right-most, center ë“±)
- **center-based methods**
    - ë™ì‘
        1. use the center point or region of objects to define positives (as foreground)
        2. predict the four distances from positives to the object boundary (four sides)
    - ex) FCOS, DenseBox, GA-RPN ë“±
- **íŠ¹ì§•**
    - anchorsì™€ ê´€ë ¨ëœ hyperparametersê°€ í•„ìš”í•˜ì§€ ì•Šë‹¤.
    - anchor-based detectorsì™€ ë¹„ìŠ·í•œ ì„±ëŠ¥ì„ ë‚¸ë‹¤.
    - generalization ability ì¸¡ë©´ì—ì„œ ì ì¬ë ¥ì´ ìˆë‹¤.

<br>

### 2.3 <span style="color: MediumVioletRed">RetinaNet</span> vs. <span style="color: RoyalBlue">FCOS</span>

#### RetinaNet

- **one-stage detector**ì˜ ê²½ìš°, ì´ë¯¸ì§€ë¥¼ gridë¡œ ë‚˜ëˆ„ì–´ ê° cellë§ˆë‹¤ bounding boxë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í•˜ë¯€ë¡œ, **positive sample(ê°ì²´ ì˜ì—­) << negative sample(ë°°ê²½ ì˜ì—­)**ì¸ ë¬¸ì œê°€ ë°œìƒí•œë‹¤.
    
    > **two-stage detector**ì˜ ê²½ìš°, region proposal ë‹¨ê³„ì—ì„œ background sampleì„ ì–´ëŠì •ë„ ì œê±°í•œë‹¤.
    
- ì´ëŸ¬í•œ **class imbalance ë¬¸ì œ**ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì‰¬ìš´ ì˜ˆì œì— ì‘ì€ ê°€ì¤‘ì¹˜ë¥¼, ì–´ë ¤ìš´ ì˜ˆì œì— í° ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ëŠ” **focal loss**ë¥¼ ë„ì…í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¨ ëª¨ë¸ì´ë‹¤.

#### FCOS

- ëª¨ë¸ì˜ ì„±ëŠ¥ì´ anchor boxì˜ ì†ì„±ì— ë¯¼ê°í•œ anchor-based ë°©ë²•ì´ ì•„ë‹Œ, **anchor-free** ë°©ë²•ì„ ë„ì…í•œ ëª¨ë¸ì´ë‹¤. (RetinaNet ì´í›„)
    
    > region proposalê³¼ anchorê°€ ëª¨ë‘ í•„ìš”í•˜ì§€ ì•Šì€ **one-stage** ëª¨ë¸ì´ë‹¤.

- feature mapì—ì„œì˜ ìœ„ì¹˜ **(x, y)ê°€ GT bounding boxì— ì†í•˜ë©´ positive sampleë¡œ ê°„ì£¼**í•œë‹¤.
- multi-level FPN êµ¬ì¡°, center-ness ë“±ì„ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼°ë‹¤.

#### Comparison

**<span style="color: MediumVioletRed">anchor-free</span> FCOS**(MS COCO dataset ê¸°ì¤€ 37.1%)ê°€ **<span style="color: RoyalBlue">anchor-based</span> RetinaNet**(32.5%)ë³´ë‹¤ ì„±ëŠ¥ì´ ë†’ë‹¤.

|  | RetinaNet | FCOS |
| --- | --- | --- |
| **Type** | one-stage <span style="color: MediumVioletRed">**anchor-based detector**</span> | center-based <span style="color: RoyalBlue">**anchor-free detector**</span> |
| **Number of anchors<br>tiled per location** | <span style="color: MediumVioletRed">**several**</span> anchor boxes per location | <span style="color: RoyalBlue">**one**</span> anchor point per location<br>(* anchor point == center of an anchor box) |
| **Definition of positive<br>and negative samples** | resorts to the <span style="color: MediumVioletRed">**IoU**</span>  | utilizes <span style="color: RoyalBlue">**spatial and scale constraints**</span><br>to select samples |
| **Regression starting<br>status** | from the preset anchor <span style="color: MediumVioletRed">**box**</span> | from the anchor <span style="color: RoyalBlue">**point**</span> |

<br>

---

## 3. Difference Analysis of Anchor-based and Anchor-free Detection

> RetinaNetê³¼ FCOSì˜ ë¹„êµë¥¼ í†µí•´ **anchor-basedì™€ anchor-free detectors ê°„ì˜ essential difference**ë¥¼ ì°¾ì•„ë³¸ë‹¤. 
{: .prompt-info}

### 3.1 Experiment setting

- **dataset** - challenging MS COCO dataset
- **training detail**
    - backbone - ImageNet pretrained ResNet-50 w/ 5-level feature pyramid structure
    - image size - shorter sideëŠ” 800, longer sideëŠ” 1,333 ì´í•˜ë¡œ
    - SGD, weight decay 0.0001, 16 batch size, initial LR 0.01
- **inference detail**
    - training phaseì™€ ë™ì¼í•˜ê²Œ resize the input image
    - preset score 0.05 â†’ filter out plenty of background bounding boxes
    - output the top 1000 detections per feature pyramid
    - NMS w/ IoU threshold 0.6 â†’ top 100 confident detections per image

<br>

### 3.2 Inconsistency Removal

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2023-01-18-1.png){: style="max-width: 70%"}

- **FCOSì˜ íŠ¹ì§• & ìƒˆë¡œìš´ ê°œì„  ì‚¬í•­** ì¤‘ anchor-based detectorsì—ë„ ì ìš©ë  ìˆ˜ ìˆëŠ” ê²ƒë“¤ì„ **RetinaNetì—ë„ ì ìš©**í•˜ì—¬ inconsistenciesë¥¼ ì œê±°í•˜ì˜€ë‹¤.
    - ê¸°ì¡´ RetinaNetì€ 9 anchors per location ì´ì§€ë§Œ, FCOSì²˜ëŸ¼ 1 anchor per locationìœ¼ë¡œ ì¡°ì •í•˜ì˜€ë‹¤. (â‡’ **RetinaNet(#A=1)**)
    - GroupNorm, GIoU Loss ë“±ì„ RetinaNetì—ë„ ì ìš©í•˜ì˜€ë‹¤.
- ê²°ê³¼ì ìœ¼ë¡œ, **anchor-free FCOS(37.8%)ì™€ anchor-based RetinaNet(37.0%)ì˜ essential gapì€ 0.8%**ì´ë‹¤.

<br>

### 3.3 Essential Differences

> **ì´ì œ, anchor-based RetinaNet(#A=1)ê³¼ anchor-free FCOSì˜ ì°¨ì´ì ì€ ë‹¤ìŒ ë¿ì´ë‹¤. ì–´ë–¤ ê²ƒì´ essential difference ì¼ê¹Œ?**
> 
> - about classification sub-task in detection
>     - ex) the way to define positive and negative samples
> - about regression sub-task
>     - ex) regression starting from an anchor box or an anchor point
{: .prompt-tip}

#### [1] Classification

> positive / negative samplesë¥¼ ì •ì˜í•˜ëŠ” ë°©ë²•

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2023-01-18-2.png){: style="max-width: 70%"}

- <span style="color: MediumVioletRed">**RetinaNet**</span>
    - different pyramid levelsì—ì„œ ë½‘ì€ anchor boxesë¥¼ positiveì™€ negativeë¡œ ë‚˜ëˆ„ê¸° ìœ„í•´ <span style="color: MediumVioletRed">**IoU**</span>ë¥¼ ì‚¬ìš©í•œë‹¤.
        
        â‡’ <span class="hlp">final positivesë¥¼ **spatial & scale dimensionì—ì„œ ë™ì‹œ**ì— ì„ íƒí•œë‹¤.</span>
        
    - IoUê°€ íŠ¹ì • threshold ($\theta_p, \theta_n$)ë¥¼ ë„˜ì§€ ëª»í•˜ë©´ í•™ìŠµ ë‹¨ê³„ì—ì„œ ë¬´ì‹œëœë‹¤.
- <span style="color: RoyalBlue">**FCOS**</span>
    - different pyramid levelsì—ì„œ ë½‘ì€ anchor pointsë¥¼ positiveì™€ negativeë¡œ ë‚˜ëˆ„ê¸° ìœ„í•´ <span style="color: RoyalBlue">**spatial & scale constraints**</span>ë¥¼ ì‚¬ìš©í•œë‹¤.
    1. GT box ì•ˆì— ìˆëŠ” anchor pointsë¥¼ **candidate positive samples**ë¡œ ê³ ë ¤í•œë‹¤.
        
        â‡’ <span class="hlp">candidate positives â†’ **spatial dimension**(constraint)ì—ì„œ</span>
        
    2. selects the **final positive samples** from candidates based on the scale range defined for each pyramid level
        
        â‡’ <span class="hlp">final positives â†’ **scale dimension**(constraint)ì—ì„œ</span>
        
    3. unselected anchor points are negative samples
- ì´ì²˜ëŸ¼ positive / negative sampleì„ ì°¾ëŠ” ë°©ë²•ì´ ë‹¤ë¥´ë‹¤.
    
    ![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2023-01-18-3.png){: style="max-width: 70%"}
    
    - **RetinaNetì´ <span style="color: RoyalBlue">spatial & scale constraint strategy</span>ë¥¼ ì‚¬ìš©í•œë‹¤ë©´** - AP performance 37.0% â†’ 37.8% (improves)
    - **FCOSê°€ <span style="color: MediumVioletRed">IoU strategy</span>ë¥¼ ì‚¬ìš©í•œë‹¤ë©´** - AP performance 37.8% â†’ 36.9% (decreases)

> **the definition of positive and negative samples** ëŠ” anchor-basedì™€ anchor-free detectors ê°„ì˜ <span style="color: crimson">**essential difference**</span> ì´ë‹¤.
{: .prompt-info}


#### [2] Regression

> positive/negative samplesê°€ ì •í•´ì§€ê³  ë‚˜ë©´, location of obejctê°€ regressed from positive samples ëœë‹¤.

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2023-01-18-4.png){: style="max-width: 70%"}

- <span style="color: MediumVioletRed">**RetinaNet**</span>
    - regresses from the **anchor box** w/ **four offsets** between the anchor box and the object box
    - regression starting status = a box
- <span style="color: RoyalBlue">**FCOS**</span>
    - regresses from the **anchor point** w/ **four distances** to the bound of object
    - regression starting status = a point
- í•˜ì§€ë§Œ, RetinaNetê³¼ FCOSê°€  **ê°™ì€ sample selection strategy to have consistent positive/negative samples**ë¥¼ ì‚¬ìš©í•œë‹¤ë©´, regressingì´ boxì—ì„œ ì‹œì‘í•˜ë“  pointì—ì„œ ì‹œì‘í•˜ë“  ìµœì¢… ì„±ëŠ¥ì— ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ì—†ë‹¤.
    - 37.0% vs. 36.9%
    - 37.8% vs. 37.8%
    
    ![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2023-01-18-5.png){: style="max-width: 70%"}
    

> the **regression starting status** is an <span style="color: crimson">**irrelevant difference**</span> rather than an essential difference
{: .prompt-info}

<br>

> one-stage anchor-based detectorì™€ center-based anchor-free detectorì˜ essential difference:
> 
> **"how to define positive and negative training samples"**
{: .prompt-warning}

<br>

---

## 4. Adaptive Training Sample Selection

- object detectorë¥¼ í•™ìŠµì‹œí‚¤ë ¤ë©´, ìš°ì„  positive / negative samples for classificationì„ ì •í•˜ê³ , **positive samplesë¥¼ regressionì— ì´ìš©**í•´ì•¼ í•œë‹¤.
- positives / negativesë¥¼ ì •ì˜í•˜ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì„ ì†Œê°œí•œë‹¤.
    - traditional IoU-based strategy(RetinaNet)ë³´ë‹¤ í–¥ìƒëœ ì„±ëŠ¥ì„ ë³´ì—¬ì¤€ë‹¤.

    > <span class="hl">**ATSS (Adaptive Training Sample Selection)**</span>
    >   - almost has no hyperparameters
    >   - robust to different settings
    {: .prompt-info}

<br>

### 4.1 Previous Sample Selection Strategies

- some sensitive hyperparametersê°€ í•„ìš”í•˜ë‹¤.
    - **<span style="color: MediumVioletRed">anchor-based</span> detectors**: IoU thresholds ë“±
    - **<span style="color: RoyalBlue">anchor-free</span> detectors**: scale ranges ë“±
- hyperparameterê°€ ë‹¤ ì„¤ì •ë˜ë©´, all GT boxesëŠ” ê³ ì •ëœ ruleì— ì˜í•´ their positive samplesë¥¼ ì„ íƒí•´ì•¼ í•œë‹¤.
    
    > ëŒ€ë¶€ë¶„ì˜ objectì—ëŠ” suitable í•˜ë‚˜, some outer objectsëŠ” neglected ëœë‹¤.

- ë”°ë¼ì„œ hyperparemter settingì— ë”°ë¼ ê²°ê³¼ê°€ ë‹¬ë¼ì§„ë‹¤.

<br>

### 4.2 ATSS(Adaptive Training Sample Selection) method

> positive / negative samplesë¥¼ objectì˜ í†µê³„ì  íŠ¹ì„±ì„ í†µí•´ ê±°ì˜ ìë™ì ìœ¼ë¡œ(= hyperparameter ì—†ì´) ë‚˜ëˆ„ëŠ” ë°©ë²•ì´ë‹¤.
> 

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2023-01-18-6.png){: style="max-width: 70%"}

1. imageì˜ ê° GT box $g$ì— ëŒ€í•´ì„œ, ê·¸ê²ƒì˜ **candidate positive samples**ë¥¼ ì°¾ëŠ”ë‹¤. 
    
    â†’ <span class="hlp">spatial dimension</span>
    
    - ê° pyramid levelì— ëŒ€í•´ì„œ, **center of $g$**ì™€ **center ê°„ì˜ L2 distance**ê°€ ê°€ì¥ ê°€ê¹Œìš´ <span style="color: crimson">$k$ anchor boxes</span>ë¥¼ ì„ íƒí•œë‹¤.
    - $\mathcal L$ feature pyramid levelsë¼ë©´, GT box $g$ëŠ” <span style="color: crimson">$k \times \mathcal L$ candidate positive samples</span>ë¥¼ ê°€ì§€ê²Œ ëœë‹¤.

2. ì´ëŸ¬í•œ candidatesì™€ GT $g$ ê°„ì˜ IoU <span style="color: crimson">$\mathcal D_g$ë¥¼ ê³„ì‚°</span>í•œë‹¤.
    - ì´ê²ƒì˜ meanì€ $m_g$, standard deviationì€ $v_g$ (â‡’ statistics)

3. candidates ì¤‘ IoUê°€ threshold $t_g$ ì´ìƒì¸ ê²ƒë“¤ì„ **final positive samples**ë¡œ ì„ íƒí•œë‹¤. 
    
    â†’ <span class="hlp">scale dimension</span>
    
    - IoU threshold for this GT $g$ëŠ” <span style="color: crimson">$t_g=m_g+v_g$</span> ë¡œ êµ¬í•œë‹¤.
    - positive samplesì˜ centerê°€ GT box ì•ˆì— ìˆëŠ” ê²½ìš°ì—ë§Œ ì„ íƒí•œë‹¤.
    - ë§Œì•½ anchor boxê°€ multiple GT boxesì— assigned ë˜ì—ˆë‹¤ë©´, highest IoUë¥¼ ê°€ì§„ ê²ƒì´ ì„ íƒëœë‹¤.

4. positive sampleë¡œ ì„ íƒë°›ì§€ ëª»í•œ ë‚˜ë¨¸ì§€ anchorsëŠ” **negative samples**ê°€ ëœë‹¤.

#### [1] anchor box - object ê°„ center distance ê¸°ë°˜ìœ¼ë¡œ candidatesë¥¼ ì„ íƒí•˜ëŠ” ì´ìœ 

- <span style="color: MediumVioletRed">**RetinaNet**</span> - center of anchor boxì™€ center of objectê°€ ê°€ê¹Œìš¸ ë•Œ IoU is larger
- <span style="color: RoyalBlue">**FCOS**</span> - closer anchor point to the center of objectê°€ produce higher-quality detections
- ë”°ë¼ì„œ closer anchor to the center of objectê°€ better candidate ì´ë‹¤.

#### [2] IoU thresholdë¡œ mean + standard deviationì„ ì‚¬ìš©í•˜ëŠ” ì´ìœ 

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2023-01-18-7.png){: style="max-width: 70%"}

- **IoU mean $m_g$ of an object** - a measure of suitability of th epreset anchors for this object
    - **high** $m_g$: high-quality candidates / IoU threshold is supposed to be high
    - **low $m_g$**: low-quality candidates / IoU threshold should be low
- **IoU standard deviation $v_g$ of an object** - a measure of which layers are suitable to detect this object
    - **high $v_g$**: í•´ë‹¹ objectì— suitableí•œ pyramid levelì´ ì¡´ì¬í•œë‹¤.
        - $v_g+m_g$ì„ thresholdë¡œ ì‚¬ìš©í•œë‹¤ëŠ” ê²ƒ = high threshold to select positives only from that level ì„ ë‚˜íƒ€ë‚¸ë‹¤.
    - **low $v_g$**: several pyramid levels suitable for this object
        - $v_g+m_g$ë¥¼ thresholdë¡œ ì‚¬ìš©í•œë‹¤ëŠ” ê²ƒ = low threshold to select appropriate positives from these levels
- ì´ì²˜ëŸ¼, sum of mean $m_g$ê³¼ standard deviation $v_g$ë¥¼ IoU threshold $t_g$ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ **objectì˜ í†µê³„ì  íŠ¹ì„±**ì— ë”°ë¼ **ì ì ˆí•œ pyramid levelsì—ì„œ positivesë¥¼ adaptively í•˜ê²Œ ì„ íƒ**í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê²ƒì´ë‹¤.

#### [3] almost hyperparameter-free

- ë³¸ ë°©ë²•ì— ì‚¬ìš©ë˜ëŠ” hyperparameterëŠ” **anchor boxì˜ ê°œìˆ˜**ì¸ $k$ ë¿ì´ë‹¤.
- ë˜í•œ, $k$ ê°’ì— ëŒ€í•´ insensitive í•˜ë¯€ë¡œ almost hyperparameter-freeë¼ê³  ê°„ì£¼í•  ìˆ˜ ìˆë‹¤.

<br>

### 4.3 Verification

> RetinaNetê³¼ FCOSì˜ sample selection strategyë¥¼ ATSSë¡œ ë°”ê¿”ë³´ê³ , ATSSì˜ effectivenessë¥¼ anchor-basedì™€ anchor-freeë¡œ ë‚˜ëˆ„ì–´ ì‚´í´ë³¸ë‹¤.
> 

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2023-01-18-8.png){: style="max-width: 70%"}

- **<span style="color: MediumVioletRed">Anchor-based</span> RetinaNetì— ì ìš©** - improve RetinaNet (#A=1)ì„ ì‚¬ìš©í•œë‹¤.
    - ì„±ëŠ¥ì´ í–¥ìƒë˜ì—ˆë‹¤. (adaptive selection of positive samples for each GT based on its statistical characteristics)
    - positive / negative samplesë¥¼ additional overhead ì—†ì´ ì¬ì •ì˜í•˜ë¯€ë¡œ ì´ improvementsëŠ” cost-freeë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤.
- **<span style="color: RoyalBlue">Anchor-free</span> FCOSì— ì ìš©** - ë‘ ê°€ì§€ versionìœ¼ë¡œ ê°€ëŠ¥í•˜ë‹¤.
    - **lite version (center sampling)**: candidate positivesë¥¼ ì„ íƒí•˜ëŠ” ë°©ë²•ë§Œ ATSSë¡œ ì ìš©
        - **FCOS** - anchor points in the object boxë¥¼ candidateë¡œ ê°„ì£¼ (plenty of low-quality positives)
        - **ATSS** - top(closest) k=9 candidates per pyramid level for each GTë¥¼ ì„ íƒ
        - 37.8% â†’ 38.6% on AP
        - í•˜ì§€ë§Œ ì—¬ì „íˆ hyperparameters of scale rangesê°€ ì¡´ì¬í•œë‹¤.
    - **full version (ATSS)**: anchor box ë„ì…
        - **FCOS** - anchor point
        - **ATSS** - anchor box w/ 8S scale to define positive and negative samples, then regress these positive samples to objects
        - significantly increases the performance (outperforms the lite version)
    
    <br>

    | --- | --- |
    | **ë‘ ë²„ì „ì˜ ê³µí†µì ** | same **candidates** selected in the <span class="hl">spatial dimension</span> |
    | **ë‘ ë²„ì „ì˜ ì°¨ì´ì ** | different ways to select **final positives from candidates** along the <span class="hl">scale dimension</span> |

<br>

### 4.4 Analysis

> ATSSëŠ” only involves on hyperparameter $k$ì™€ one related setting of anchor boxes
> 

#### Hyperparameter $k$

> each pyramid levelì—ì„œ candidate positive samplesë¥¼ ë½‘ì„ ë•Œ ì‚¬ìš©
> 

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2023-01-18-9.png){: style="max-width: 70%"}

- **too large $k$** â‡’ too many low-quality candidates
- **too small $k$** â‡’ too few candidate positive samples â†’ statistical instability
- $k$ê°€ 7 ~ 17 ì¸ ê²½ìš°, ì„±ëŠ¥ì´ ê½¤ë‚˜ insensitive í•˜ì˜€ë‹¤.
    - quite robustness & can be enarly regarded as hyperparameter-free

#### Anchor Size

> ATSSëŠ” resorts to the anchor boxes to define positives

- (ì´ì „ ì‹¤í—˜) one square anchor with 8S(S = the total stride size of the pyramid level) is tiled per location
- **different <span class="red">scales</span> of the square anchor** - performances are quite stable
    
    ![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2023-01-18-10.png){: style="max-width: 70%"}
    
- **different <span class="red">aspect ratios</span> of the 8S anchor box** - insensitive to this variation
    
    ![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2023-01-18-11.png){: style="max-width: 70%"}
    
> ATSSëŠ” different anchor settingsì— ëŒ€í•´ robust í•˜ë‹¤.
{: .prompt-info}

<br>

### 4.5 Comparison

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2023-01-18-13.png)

- ë‹¤ë¥¸ methodsì™€ ê°™ì€ backbone ëª¨ë¸ì„ ì‚¬ìš©í–ˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  Cascade R-CNN, C-Mask RCNN, RetinaNet ë“±ì˜ ì„±ëŠ¥ì„ ì•ì§ˆë €ë‹¤.
    - further improve (w/ larger backbone)ë¡œ ì„±ëŠ¥ì„ ë” ë†’ì¼ ìˆ˜ ìˆë‹¤.
    - ~~ë‹¹ì‹œì˜ all the anchor-free and anchor-based detectorë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ì•˜ë‹¤. (SNIP ì œì™¸í•˜ê³ . 0.1% lower)~~
- **ATSSëŠ” positive / negative samplesì˜ ì •ì˜ì— ê´€í•œ ê²ƒì´ë¯€ë¡œ, ëŒ€ë¶€ë¶„ì˜ ë‹¤ë¥¸ ê¸°ë²•ì— compatible & complementary í•˜ë‹¤.**
- DCN(Deformable Convolutional Networks)ë„ ì‚¬ìš©í•´ë³¸ ê²°ê³¼, APê°€ ë˜ ì¦ê°€í–ˆë‹¤. (single-model & single-scale testing)
- multi-scale testing strategyê¹Œì§€ ì ìš©í•˜ë‹ˆ 50.7% APê¹Œì§€ ë‹¬ì„±í•  ìˆ˜ ìˆì—ˆë‹¤.

<br>

### 4.6 Discussion

> **anchor-based ì™€ anchor-freeì˜ difference ì¤‘ ì•„ì§ ë‹¤ë£¨ì§€ ì•Šì€ ê²ƒ:**
> 
> the number of anchors tiled per location
{: .prompt-tip}

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2023-01-18-14.png){: style="max-width: 70%"}

- ì§€ê¸ˆê¹Œì§€ ì‹¤í—˜ë“¤ì€ FCOSì™€ì˜ ë¹„êµë¥¼ ìœ„í•´ **RetinaNet(#A=1, one anchor per location)**ë¡œ ì§„í–‰í–ˆë‹¤.
- ì›ë˜ì˜ **RetinaNetì€ (#A=9),** ì¦‰, **9 anchors per location** (3 scales Ã— 3 aspect ratios)ì´ë‹¤.
    - table 1ì˜ universal improvements ì ìš©í•˜ë©´ AP performance í–¥ìƒëœë‹¤.
    - ATSS ì‚¬ìš©í•˜ì§€ ì•Šê³ ì„œë„ ì´ improved RetinaNet(#A=9)(38.4%)ê°€ RetinaNet(#A=1)(37.0%)ë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ì•˜ë‹¤.
    - ì¦‰, <span class="hl">**traditional IoU-based sample selection strategy**ë¥¼ ì‚¬ìš©í•œë‹¤ë©´, tiling more anchor boxes per locationì€ íš¨ê³¼ì </span>ì´ë‹¤.
- í•˜ì§€ë§Œ **ATSS**ë¥¼ ì‚¬ìš©í•œë‹¤ë©´?
    - improved RetinaNet(#A=9)ì™€ RetinaNet(#A=1)ì— ëª¨ë‘ ATSSë¥¼ ì ìš©í•´ë´¤ì„ ë•Œ, ë¹„ìŠ·í•œ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤. (3, 6 line)
    - number of anchor scalesë‚˜ aspect ratiosë¥¼ 3ì—ì„œ 1ë¡œ ë°”ê¾¸ì–´ë³´ì•„ë„ ì„±ëŠ¥ì— í¬ê²Œ ë³€í™”ê°€ ì—†ë‹¤. (line 4, 5)

<br>

> ì¦‰, positive samplesê°€ ì ì ˆí•˜ê²Œ ì„ íƒë˜ê¸°ë§Œ í•œë‹¤ë©´, ê° locationë§ˆë‹¤ ì–¼ë§ˆë‚˜ ë§ì€ anchorë¥¼ ë‘ëŠ”ì§€ì™€ëŠ” ìƒê´€ ì—†ì´ ê²°ê³¼ëŠ” ê°™ë‹¤.
>
> â†’ <span class="hl">**ATSS**ë¥¼ ì‚¬ìš©í•œë‹¤ë©´, tiling multiple anchors per locationì€ useless operationì´ë‹¤.</span>
{: .prompt-info}

<br>

---

## 5. Conclusion

1. one-stage anchor-basedì™€ center-based anchor-free detectorì˜ essential differenceëŠ” **positive / negative training samplesë¥¼ ì •ì˜í•˜ëŠ” ë°©ë²•**ì´ë‹¤. 
    
2. ATSSëŠ” objectì˜ **í†µê³„ì  íŠ¹ì§•**ì„ ì´ìš©í•˜ì—¬ ìë™ìœ¼ë¡œ **positive / negative training samples**ë¥¼ ë‚˜ëˆˆë‹¤.
    
    > â†’ bridging the gap between anchor-based and anchor-free detectors
    
3. ATSSë¥¼ ì‚¬ìš©í•œë‹¤ë©´ tiling multiple anchors per locationì´ ìœ ìš©í•œ ë„êµ¬ê°€ ì•„ë‹ ìˆ˜ ìˆë‹¤.

4. ATSSë¥¼ í†µí•´ overhead ì—†ì´ detection ë¶„ì•¼ì—ì„œì˜ SOTA performanceë¥¼ ì´ë£° ìˆ˜ ìˆë‹¤.
