---
title: "[Paper] Structure Inference Net: Object Detection Using Scene-Level Context and Instance-Level Relationships"
date: 2022-11-16 19:50:00 +0900
categories: [Deep Learning, Paper Review]
tags: [paper review, object detection]
math: true
---

> ğŸ“ Paper: <https://arxiv.org/abs/1807.00119>

<br>

**ë¬¼ì²´ ê°„ì˜ ê´€ê³„**(instance-level relationship)ë¥¼ ì´ìš©í•˜ì—¬ object detectionì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê³  ì‹¶ì–´ ì½ì–´ë´¤ë˜ ë…¼ë¬¸ì´ë‹¤.

<br>

## 1. Introduction

ê¸°ì¡´ì˜ object detection ê´€ë ¨ ì—°êµ¬ëŠ” **objectì˜ region of interest ê·¼ì²˜ì˜ local information**, ì¦‰ **visual appearance**ì—ë§Œ ì§‘ì¤‘í–ˆë‹¤.

í•˜ì§€ë§Œ ì£¼ë¡œ ì´ë¯¸ì§€ëŠ” **contextual information(scene context + object relationships)** ë˜í•œ ê°€ì§€ê³  ìˆë‹¤. ì´ë¥¼ ë¬´ì‹œí•˜ëŠ” ê²ƒì€ object detectionì˜ accuracyì— ì œí•œì„ ì¤„ ìˆ˜ ë°–ì— ì—†ë‹¤.

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2022-11-16-1.png){: style="max-width: 70%"}

ì´ëŸ¬í•œ contextual informationì„ ì´ìš©í•˜ì—¬ object detectionì„ **cognition problem** ë¿ë§Œ ì•„ë‹ˆë¼ **inference problem**ìœ¼ë¡œë„ ì ‘ê·¼í•  ìˆ˜ ìˆë‹¤. 

ê° image ë§ˆë‹¤ ì–»ì–´ì§„ **tailored graph**ë¥¼ ì´ìš©í•˜ë©°, objectëŠ” **scene**ê³¼ **ìƒê´€ ê´€ê³„ê°€ ë†’ì€ ë‹¤ë¥¸ objectë“¤**ë¡œë¶€í„° **messageë¥¼ ì „ë‹¬**ë°›ê²Œ ëœë‹¤. 

ì´ë¥¼ í†µí•´ **object state**ëŠ” **scene context**ì™€ **object relationship**ì˜ ì˜í–¥ì„ ë°›ê²Œ ë˜ë©°, ì´ëŠ” categoryì™€ locationì„ ê²°ì •í•˜ëŠ” ë°ì— ì´ìš©ëœë‹¤.

![node = object / edge = object relationship](/assets/img/posts/Deep-Learning/Paper-Review/2022-11-16-2.png){: style="max-width: 70%"}
_node = object / edge = object relationship_

<br>

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” graph ë‚´ì—ì„œì˜ object stateë¥¼ ì¶”ë¡ í•˜ê¸° ìœ„í•´ **Structure Inference Network(SIN)**ì„ ì œì•ˆí•œë‹¤. 

- ë‚´ë¶€ì—ëŠ” **object state**ì— ì—¬ëŸ¬ ì¢…ë¥˜ì˜ messages(from scene and different objects)ë¥¼ encode í•˜ê¸° ìœ„í•œ **memory cell**ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, **Gated Recurrent Units(GRUs)**ë¡œ êµ¬ì„±ëœë‹¤.
- GRUì˜ initial stateëŠ” object representationìœ¼ë¡œ ê³ ì •í•˜ë©°, ê° messageë¥¼ ì…ë ¥í•˜ì—¬ object stateë¥¼ update í•´ë‚˜ê°„ë‹¤.
- í•´ë‹¹ ë°©ë²•ì€ íŠ¹ì • detection frameworkì— í•œì •ë˜ì§€ ì•ŠëŠ”ë‹¤.

<br>

---

## 2. Related Work

### Object Detection

ì£¼ë¡œ **region proposals based methods(two-stage detectors)**ì™€ **proposal-free methods(one-stage detectors)**ë¡œ ë‚˜ë‰œë‹¤.

- **two-stage detectors**ë¡œëŠ” R-CNN, Fast R-CNN, Faster R-CNN ë“±ì´ ìˆìœ¼ë©°, first stageì—ì„œëŠ” candidate boxesë¥¼ ìƒì„±í•˜ê³ , second stageì—ì„œëŠ” í•´ë‹¹ boxesë¥¼ classify í•œë‹¤.
- **one-stage detectors**ë¡œëŠ” SSDì™€ YOLO ë“±ì´ ìˆìœ¼ë©°, real-time detectionì— ì í•©í•˜ë‹¤.

í•˜ì§€ë§Œ **í•˜ë‚˜ì˜ imageì—ì„œ ë‹¤ë¥¸ objectsë¥¼ detect í•˜ëŠ” ê²ƒ**ì€ í•­ìƒ **isolated task**ë¡œ ê°„ì£¼ë˜ì–´ ì™”ë‹¤. (íŠ¹íˆ two-stage detectorsì—ì„œ)

ë”°ë¼ì„œ vague featureë¥¼ ê°€ì§„ ì‘ì€ objectì— ëŒ€í•´ì„œëŠ” ëŒ€ì‘í•˜ê¸° ì–´ë ¤ì› ë‹¤.

<br>

### Contextual Information

**context around object or scene-level context**ë¥¼ ì´ìš©í•˜ëŠ” ì—°êµ¬(ION, GBD-Net, using segmentation, etc.)ëŠ” ê½¤ ì§„í–‰ë˜ì–´ ì™”ìœ¼ë‚˜, **object-object relationship**ì„ ì´ìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ì„œëŠ” í° ë°œì „ì´ ì—†ì—ˆë‹¤.

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ë‘ ê°€ì§€ ì •ë³´ë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•œë‹¤.

<br>

### Structure Inference

**deep networks**ì™€ structured prediction taskë¥¼ ìœ„í•œ **graphical models**ë¥¼ ê²°í•©í•œ ì—°êµ¬ë“¤ì´ ì§„í–‰ë˜ì–´ ì™”ë‹¤. (structure inference machines, Structural-RNN, graph inference model, etc.)

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” object detection taskë¥¼ graph structure inference problemìœ¼ë¡œ ì ‘ê·¼í•œë‹¤.

<br>

---

## 3. Method

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2022-11-16-3.png)

- **ë°˜ë³µì ìœ¼ë¡œ node stateë¥¼ update** í•´ë‚˜ê°€ë©°, ê° nodeì˜ **final state**ëŠ” í•´ë‹¹ ROIì˜ **categoryë¥¼ ì˜ˆì¸¡**í•˜ê³  **locationì„ ì •ì œ**í•˜ëŠ” ë°ì— ì‚¬ìš©ëœë‹¤.
- ì „ì²´ framework(ë³¸ ì—°êµ¬ì—ì„œëŠ” Faster R-CNN)ëŠ” **end-to-end**ë¡œ í•™ìŠµë˜ë©° original multi-task lossë¥¼ ì‚¬ìš©í•œë‹¤. (base object detection frameworkì™€ ìƒê´€ ì—†ì´ ì ìš© ê°€ëŠ¥í•˜ë‹¤.)

<br>

### Graphical Modeling

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2022-11-16-4.png){: style="max-width: 70%"}

- **Graph $$G = (V, E, s)$$**
    - $$v \in V$$ (`node`) - region proposals
    - $$s$$ (`scene`) - scene of the image
    - $$e \in E$$ (`edge`) - relationship between each pair of object nodes
- **íë¦„**
    1. Region Proposal Network(RPN)ì—ì„œ objectê°€ ë“¤ì–´ìˆì„ ë²•í•œ **region proposals**ë¥¼ ìƒì„±í•œë‹¤.
    2. Non-Maximum Suppression(NMS)ì„ í†µí•´ ê³ ì •ëœ ìˆ˜ì˜ **ROIs(Region of Interest)**ë¥¼ ì–»ëŠ”ë‹¤.
    3. ê° ROI $$v_i$$ì— ëŒ€í•´, ROI pooling layer ì´í›„ì˜ FC layerë¥¼ ì´ìš©í•˜ì—¬ **visual feature** $$f_i^v$$ë¥¼ ì¶”ì¶œí•œë‹¤.
    4. scene labelì— ëŒ€í•œ ground-truth labelì´ ì—†ìœ¼ë¯€ë¡œ **whole image visual feature $$f^s$$**ë¥¼ scene representationìœ¼ë¡œ ì‚¬ìš©í•œë‹¤. (nodeì™€ ê°™ì€ ì—°ì‚°)
    5. $$v_i$$ì— ëŒ€í•œ $$v_j$$ì˜ influenceë¥¼ ë‚˜íƒ€ë‚´ëŠ” **directed edge $$e_{j\rightarrow i}$$** ë¥¼ spatial featureì™€ visual featureë¥¼ ì´ìš©í•˜ì—¬ êµ¬í•œë‹¤.

<br>

### Message Passing

nodeê°€ interaction í•˜ëŠ” ë°©ë²•ì€ **sceneê³¼ ë‹¤ë¥¸ nodesë¡œë¶€í„° ì „ë‹¬ ë°›ì€ messages**ë¥¼ encode í•˜ëŠ” ê²ƒì´ë‹¤. ë”°ë¼ì„œ ì—¬ëŸ¬ **incoming messagesë¥¼ ê¸°ì–µ**í•˜ê³ , ì˜ë¯¸ìˆëŠ” **representationìœ¼ë¡œ ë³€í™˜**í•´ì•¼ í•œë‹¤.

long-term informationì— íš¨ê³¼ì ì¸ memory machine ì²˜ëŸ¼ ë™ì‘í•˜ëŠ” RNN ì¤‘ì—ì„œ **GRU**ë¥¼ ì‚¬ìš©í•œë‹¤.

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2022-11-16-5.png){: style="max-width: 70%"}

- reset gate $$r$$:

    $$
    r = Ïƒ(W_r[x,h_t])
    $$

- update gate $$z$$:

    $$
    z = Ïƒ(W_z[x,h_t]) 
                    
                
            
    $$

- actual activation:

    $$
    h_{t+1}=zh_t+(1âˆ’z)\tilde h, \newline 
    \tilde h = \phi(W_x + U(r âŠ™ h_t))
    $$

<br>

> reset gateë¥¼ í†µí•´ì„œ ê´€ë ¨ ì—†ëŠ” informationì€ drop ë˜ë©°, update gateë¥¼ í†µí•´ì„œ ë” compactí•œ representationì´ ë‚¨ê²Œ ëœë‹¤.
{: .prompt-info}

|                          | encoding message from <span style="color: RoyalBlue">**scene**</span> | encoding message from <span style="color: RoyalBlue">**other objects**</span> |
| ------------------------ | --------------------------------------------------------------------- | ----------------------------------------------------------------------------- |
| **initial state of GRU** | object details                                                        | object details                                                                |
| **input**                | message from scene                                                    | integrated message from other nodes                                           |
| **ê¸°íƒ€**                 | scene contextì™€ ê´€ë ¨ ì—†ëŠ” ë¶€ë¶„ì€ ignore                               | objectì˜ stateê°€ updateë˜ë©´ objects ê°„ì˜ relationshipë„ ë³€í™”í•¨                |

<br>

### Structure Inference

> ë‘ ì¢…ë¥˜ì˜ messagesë¥¼ encode í•˜ê¸° ìœ„í•´ **scene GRUs**ì™€ **edge GRUs**ê°€ ì‚¬ìš©ëœë‹¤. (scene / other objects â†’ node ë¡œ propagate)
{: .prompt-info}

- **scene GRU**
    - **initial hidden state** - node visual feature $$f^v$$
    - **input** - scene message $$m^s$$ (= fixed scene context $$f^s$$)
- **edge GRU**
    - **integrated message $$m_e$$**ë¥¼ ë¯¸ë¦¬ ê³„ì‚°í•´ì•¼ í•œë‹¤.
    - í•œ nodeì— ëŒ€í•´ ì—¬ëŸ¬ objectë“¤ì´ ë‹¤ë¥´ê²Œ contribute í•˜ë¯€ë¡œ, ëª¨ë“  **object-object relationship $$e_{j\rightarrow i}$$** ì„ **scalar weight**ë¡œ ëª¨ë¸ë§ í•´ì•¼ í•œë‹¤. ì´ëŠ” <span style="color: RoyalBlue">**relative object position**</span>ê³¼ <span style="color: MediumVioletRed">**visual clues**</span>ë¥¼ í† ëŒ€ë¡œ ê²°ì •ëœë‹¤.
    - **node $$v_i$$ë¡œì˜ integrated message**ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°í•œë‹¤.
        
        $$
        m_i^e=\max_{j\in V}pooling (e_{j\rightarrow i}*f_j^v), \newline e_{j\rightarrow i}=relu(W_pR_{j\rightarrow i}^p)*tanh(W_v[f_i^v, f_j^v])
        $$
        
        - **max-pooling**ì„ ì´ìš©í•˜ëŠ” ì´ìœ ëŠ” mean-poolingì„ ì´ìš©í•œë‹¤ë©´ ë§ì€ ìˆ˜ì˜ ìƒê´€ ì—†ëŠ” ROIsì— ì˜í•´ messageê°€ ë°©í•´ë°›ì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤.
        - <span style="color: MediumVioletRed">**visual relationship vector**</span>ëŠ” visual featureë¥¼ concat í•˜ì—¬ ë§Œë“ ë‹¤.
        - <span style="color: RoyalBlue">**spatial position relationship**</span>ì€ ë‹¤ìŒê³¼ ê°™ì´ êµ¬í•œë‹¤. (ROIì˜ ìœ„ì¹˜ ì •ë³´ ì´ìš©)
            
            ![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2022-11-16-6.png){: style="max-width: 70%"}
            
    - **input** - new object-object message

node $$v_i$$ëŠ” sceneê³¼ ë‹¤ë¥¸ nodesë¡œë¶€í„° messagesë¥¼ ë°›ìœ¼ë¯€ë¡œ, ì´ë¥¼ ëª¨ë‘ ì´ìš©í•˜ì—¬ **node state $$h_{t+1}$$**ë¥¼ êµ¬í•œë‹¤. ì´ëŠ” GRUì˜ **ë‹¤ìŒ hidden stateë¡œ ì…ë ¥**ëœë‹¤.

$$
h_{t+1}=\frac{h_{t+1}^s+h_{t+1}^e}{2}
$$

- $$h_{t+1}^s$$ = scene GRUì˜ ê²°ê³¼ / $$h_{t+1}^e$$ = edge GRUì˜ ê²°ê³¼
- mean-poolingì´ ê°€ì¥ íš¨ìœ¨ì ì´ì—ˆë‹¤.
- ì´ë¥¼ ì´ìš©í•˜ì—¬ object categoryì™€ bounding box offsetsë¥¼ ê³„ì‚°í•œë‹¤.

<br>

---

## 4. Results

### Implementation Details

- **dataset** - PASCAL VOC, MS COCO
- **backbone** - VGG-16 pre-trained on ImageNet
- **detector (baseline)** - Faster R-CNN
- â€¦

<br>

### Overall Performance

**PASCAL VOC** (20 categories)

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2022-11-16-7.png)

**MS COCO** (more challenging dataset)

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2022-11-16-8.png)

<br>

---

## 5. Design Evaluation

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2022-11-16-9.png)

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2022-11-16-10.png){: style="max-width: 60%"}

### Scene Module

> node feature update ì‹œ scene contextual informationë§Œ ì‚¬ìš©í•œ ê²½ìš° (= scene GRUsë§Œ ì‚¬ìš©)
{: .prompt-info}

- **scene contextì™€ ìƒê´€ê´€ê³„ê°€ ë†’ì€ categories**(ex. aeroplane, bird, boat, table, train, tv ë“±)ì— ëŒ€í•´ì„œ ì„±ëŠ¥ í–¥ìƒì´ í¬ê²Œ ë‚˜íƒ€ë‚¬ë‹¤.
- baselineê³¼ ë¹„êµí–ˆì„ ë•Œ **occlusion, truncation, area sizeì™€ part visibility** ë¶€ë¶„ì—ì„œ ë” robust í•˜ë‹¤.

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2022-11-16-11.png){: style="max-width: 70%"}

- **VOC ë°ì´í„°ì…‹**ì—ì„œëŠ” XS í¬ê¸°ì˜ bird, boad, cat categoryì—ì„œ ì„±ëŠ¥ í–¥ìƒì´ ìˆì—ˆìœ¼ë©°, **COCO ë°ì´í„°ì…‹**ì—ì„œë„ small objectì— ëŒ€í•œ ì„±ëŠ¥ì¸ $$AP^S$$ê°€ í–¥ìƒë˜ì—ˆë‹¤.

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2022-11-16-12.png){: style="max-width: 70%"}

- **ì‹¤ì œ ì˜ˆì‹œ**
    
    (c), (f) - failure caseì´ë‹¤. global scene contextì˜ ì¤‘ìš”ë„ë¥¼ weighting í•˜ì—¬ general casesì™€ rare casesì˜ balanceë¥¼ ë§ì¶”ëŠ” ë°©í–¥ìœ¼ë¡œ ê°œì„ í•  ìˆ˜ ìˆë‹¤.
    
    ![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2022-11-16-13.png){: style="max-width: 70%"}
    

<br>

### Edge Module

> edge GRUsë§Œ ì‚¬ìš©
{: .prompt-info}

- ëŒ€ë¶€ë¶„ì˜ ì¹´í…Œê³ ë¦¬ë“¤ì˜ **localization ì„±ëŠ¥ì´ í–¥ìƒ**ë˜ì—ˆë‹¤.
    
    aeroplaneê³¼ busì— ëŒ€í•´ False Positiveë¥¼ ë¶„ì„í•œ ê²°ê³¼, localization ì˜¤ë¥˜ë¡œ ì¸í•œ false positiveì˜ ë¹„ìœ¨ì´ í¬ê²Œ ì¤„ì—ˆë‹¤.
    
    ![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2022-11-16-14.png){: style="max-width: 70%"}
    
- Faster R-CNNì—ì„œ ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œì¸ **â€˜í•˜ë‚˜ì˜ objectë¥¼ 2ê°œ ì´ìƒì˜ bboxì—ì„œ ë¹„ìŠ·í•œ categoriesë¡œ íŒë‹¨í•˜ëŠ” ë¬¸ì œâ€™ë¥¼ í¬ê²Œ ê°œì„ **í•˜ì˜€ë‹¤. (object relationship ì‚¬ìš©)
    
    ![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2022-11-16-15.png){: style="max-width: 70%"}
    
- **object relationshipì´ ì˜ í•™ìŠµë˜ì—ˆëŠ”ì§€ maximum $$e_{j\rightarrow i}$$ë¥¼ ì‹œê°í™” í•œ ê²°ê³¼**
    
    ![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2022-11-16-16.png){: style="max-width: 70%"}
    

<br>

### Ensemble

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2022-11-16-17.png){: style="max-width: 60%"}

- scene moduleê³¼ edge moduleì˜ hidden state $$h^s$$ì™€ $$h^e$$ë¥¼ **mean-pooling** í•˜ì—¬ fusion í•˜ëŠ” ê²ƒì´ ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ì•˜ë‹¤.
- í•™ìŠµ ì‹œ **time stepsê°€ 2**ì¼ ë•Œ ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ì•˜ë‹¤. (ë” ëŠ˜ì–´ë‚˜ë©´ message communicationì˜ close loopë¥¼ í˜•ì„±í•  ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ)
- baselineì— ë¹„í•´ **precisionì€ ë†’ê³ , recallì€ ë¹„ìŠ·**í–ˆë‹¤.
    
    ![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2022-11-16-18.png){: style="max-width: 70%"}
    
    - ì´ëŠ” ê°™ì€ ìˆ˜ì˜ positive instancesë¥¼ recallí•  ë•Œ, **SINì˜ detection ê²°ê³¼ê°€ ë” ì ê³  ë” ì •í™•í•˜ë‹¤**ëŠ” ê²ƒì„ ëœ»í•œë‹¤.
    - recallì´ í–¥ìƒë˜ì§€ ëª»í•œ ê²ƒì€ additional relationshipì´ rare case(ex. a boat lies on a street)ì— ëŒ€í•´ì„œëŠ” ë°©í•´ìš”ì†Œë¡œ ì‘ìš©í–ˆê¸° ë•Œë¬¸ì´ë‹¤.

<br>

---

## 6. Conclusion

- scene contextì™€ ìƒê´€ê´€ê³„ê°€ ë†’ì€ categoriesì— ëŒ€í•´ì„œ **scene-level context**ê°€ ìœ ìš©í–ˆë‹¤.
- **instance-level relationships** ë˜í•œ detection ì„±ëŠ¥ í–¥ìƒì— ì¤‘ìš”í•œ ì—­í• ì„ í•˜ì˜€ìœ¼ë©°, íŠ¹íˆ object localization accuracyë¥¼ í¬ê²Œ ê°œì„ í–ˆë‹¤.
