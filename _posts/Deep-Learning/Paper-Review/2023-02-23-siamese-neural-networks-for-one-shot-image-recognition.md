---
title: "[Paper] Siamese Neural Networks for One-shot Image Recognition"
date: 2023-02-23 19:50:00 +0900
categories: [Deep Learning, Paper Review]
tags: [paper review, one shot, siamese]
math: true
---

> ğŸ“ Paper: <https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf>

<br>

## 1. Introduction

### 1.1 One-Shot Learning

- test instanceì— ëŒ€í•´ ì˜ˆì¸¡í•˜ê¸° ì „, ê° class ë§ˆë‹¤ í•˜ë‚˜ì˜ example ë§Œì„ í•™ìŠµí•  ìˆ˜ ìˆë‹¤.
- evaluate ì‹œì— ë¶„ë¥˜í•  í´ë˜ìŠ¤ì˜ ê°œìˆ˜(= n)ì— ë”°ë¼ <span class="hl">**n-way one-shot task**</span>ë¼ê³  í•œë‹¤.

    > ex) ë¶„ë¥˜í•  í´ë˜ìŠ¤ê°€ 25ê°œë¼ë©´ 25-way one-shot task (â†’ ëœë¤ìœ¼ë¡œ ì˜ˆì¸¡í•  ë•Œì˜ í™•ë¥  = 4%)

#### Related Work (Baseline)

- **1-Nearest Neighbor**
    - ë‹¨ìˆœíˆ test imageì—ì„œ Euclidean Distanceë¡œ ê°€ì¥ ê°€ê¹Œìš´ í•™ìŠµ ì´ë¯¸ì§€ì™€ ê°€ê¹Œìš´ ê²ƒì„ ì„ íƒí•˜ëŠ” ë°©ë²•ì´ë‹¤.
    - 20-way one-shot taskì—ì„œ ì •í™•ë„ = 21.7%
- **HBPL(Hierarchical Bayesian Program Learning)**
    - generative í•˜ê²Œ ë¬¸ìë¥¼ ê·¸ë¦¬ëŠ” ê³¼ì •ì„ ëª¨ë¸ë§í•˜ì—¬ imageë¥¼ ì‘ì€ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆˆë‹¤.
    - í•œ íšì´ ê·¸ë ¤ì§ˆ ë•Œë§ˆë‹¤ ì•ìœ¼ë¡œ ì–´ë–»ê²Œ íšì´ ê·¸ë ¤ì§ˆì§€ prior distributionì„ ì‚¬ìš©í•˜ì—¬ ê¸€ìë¥¼ ìƒì„±í•œë‹¤.
    - 20-way one-shot taskì—ì„œ ì •í™•ë„ = 95.2%
    - ë‹¨ì : raw pixelì´ ì•„ë‹Œ íšì— ëŒ€í•œ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„± ëª¨ë¸ì„ í•™ìŠµí•˜ë¯€ë¡œ ë°ì´í„°ì…‹ì„ êµ¬í•˜ê¸°ê°€ ë§¤ìš° ì–´ë µë‹¤.

#### Deep Networks for One-Shot Learning

- ì¼ë°˜ì ì¸ Cross Entropyë¡œëŠ” One-Shot Learningì´ ë¶ˆê°€ëŠ¥í•œ ì´ìœ  = **overfitting**
- ìˆ˜ë§ì€ parameter ë•Œë¬¸ì— ì†Œìˆ˜ì˜ ë°ì´í„°ë¡œëŠ” í•™ìŠµì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤.

<br>

### 1.2 Approach: Supervised Metric-based Approach

- **siamese neural network**ë¥¼ ì‚¬ìš©í•˜ì—¬ image representationì„ í•™ìŠµí•œë‹¤.
    1. generic image featureë¥¼ í•™ìŠµí•  ìˆ˜ ìˆë‹¤.
    2. source dataì—ì„œ sampling ëœ pairsë¥¼ ì´ìš©í•˜ì—¬ standard optimization techniquesë¡œ ì‰½ê²Œ í•™ìŠµí•  ìˆ˜ ìˆë‹¤.
    3. íŠ¹ì • domain-specific knowledgeì— ì˜ì¡´í•˜ì§€ ì•ŠëŠ”ë‹¤.
- one-shot learningì„ ìœ„í•´ í•´ë‹¹ networkì˜ featureë¥¼ ì¬ì‚¬ìš© í•œë‹¤. (w/o retraining)
- í•™ìŠµëœ neural networkëŠ” image pairsì˜ class-identity ê°„ discriminateê°€ ê°€ëŠ¥í•´ì•¼ í•œë‹¤. (â‡’ verification taskë¥¼ ì˜ í•´ì•¼ í•œë‹¤!)
    - input pairsê°€ ì„œë¡œ ê°™ê±°ë‚˜ ë‹¤ë¥¸ classì— ì†í•  í™•ë¥ ì„ ì´ìš©í•˜ì—¬ í•™ìŠµí•œë‹¤.
    - ì´ë ‡ê²Œ í•™ìŠµí•œ ëª¨ë¸ì€ ìƒˆë¡œìš´ ì´ë¯¸ì§€(= ìƒˆë¡œìš´ class ë§ˆë‹¤ í•˜ë‚˜ì˜ ì´ë¯¸ì§€)ì— ëŒ€í•´ evaluate í•  ìˆ˜ ìˆë‹¤.
    - test imageì™€ pairwise ë°©ë²•ìœ¼ë¡œ, highest scoreì¸ pairingì´ highest probabilityë¥¼ ê°€ì§€ê²Œ ëœë‹¤.

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2023-02-23-1.png){: style="max-width: 70%"}

<br>

> - **train**: verification task (useful & robust í•œ feature í•™ìŠµ)
> - **test**: one-shot task (ë§ëŠ” class ì°¾ê¸°)
{: .prompt-info}

<br>

---

## 2. Siamese Network

### 2.1 Introduction

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2023-02-23-2.png){: style="max-width: 70%"}

- ì„œë¡œ ë‹¤ë¥¸ inputì„ ì…ë ¥ìœ¼ë¡œ ë°›ì§€ë§Œ, ìµœìƒë‹¨ì— energy functionìœ¼ë¡œ join ë˜ì–´ ìˆëŠ” twin networksë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤.
    - twin networkì˜ parameterëŠ” tied ë˜ì–´ ìˆë‹¤. (= weightë¥¼ share í•œë‹¤.)
    - twin networkëŠ” symmetric í•˜ë‹¤. (= ë‘ inputì˜ ìˆœì„œê°€ ë°”ë€Œì–´ë„ top conjoining layerì˜ ê²°ê³¼ëŠ” ê°™ë‹¤.)
- twin feature vectors $\mathbf h_1$ì™€ $\mathbf h_2$ ê°„ì˜ **weighted L1 distance**ë¥¼ ì´ìš©í•œë‹¤.
    - sigmoid activationì„ í†µí•´ interval [0, 1]ìœ¼ë¡œ mapping í•œë‹¤.
    - train ì‹œì— cross-entropy objectiveë¥¼ ì‚¬ìš©í•œë‹¤.

<br>

### 2.2 Model

- $L$ layers (ê° layer ë§ˆë‹¤ $N_l$ units)
    
    | --- | --- |    
    | **ì•ì˜ $L-2$ layers** |  ReLU unit ì‚¬ìš© |
    | **ë‚˜ë¨¸ì§€ layers** | sigmoidal unit ì‚¬ìš© |
- ê° layerì—ì„œì˜ $k$ th filter map (ReLU â†’ max-pool w/ filter size & stride 2)
    
    $$
    a_{1,m}^{(k)}=\text{max-pool}(\max(0, \mathbf W_{l-1,l}^{(k)}*\mathbf h_{1, (l-1)}+\mathbf b_l),2)
    $$
    
    $$
    a_{2,m}^{(k)}=\text{max-pool}(\max(0, \mathbf W_{l-1,l}^{(k)}*\mathbf h_{2, (l-1)}+\mathbf b_l),2)
    $$

    | --- | --- |    
    | $\mathbf W_{l-1,l}$ | layer $l$ì˜ feature mapì„ ë‚˜íƒ€ë‚´ëŠ” 3-dim tensor |
    | $\mathbf h_{1, l}$ | first twinì˜ layer $l$ì˜ hidden vector |
- **ì „ì²´ convolutional architecture**
    
    ![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2023-02-23-3.png)
    
    1. convolutional layers
    2. fully-connected layer (+ sigmoid)
        - ê° twin networkì—ì„œ ë‚˜ì˜¤ëŠ” feature vectorë¥¼ í†µí•´ L1 Normì„ êµ¬í•œë‹¤.
        - prediction vector $\mathbf p = \sigma (\sum_j \alpha_j \vert\mathbf h_{1, L-1}^{(j)}-\mathbf h_{2, L-1}^{(j)}\vert)$
    3. a layer computing the induced distance metric (+ sigmoid)
        - (L-1)th hidden layerì—ì„œ í•™ìŠµëœ feature spaceì—ì„œì˜ metricì„ ê³„ì‚°í•œë‹¤.
        - sigmoid í•¨ìˆ˜ë¥¼ í†µí•´ two feature vectors ê°„ì˜ similarityë¥¼ score í•œë‹¤.
        - $\alpha_j$ = component-wise distanceì˜ importanceë¥¼ weighting í•˜ëŠ” parameter (í•™ìŠµë¨)

<br>

### 2.3 Learning

- loss functionìœ¼ë¡œëŠ” **regularized cross-entropy objective**ë¥¼ ì‚¬ìš©í•œë‹¤.
    - ì§ì ‘ì ìœ¼ë¡œ same class ë¼ë¦¬ëŠ” ê°€ê¹ê²Œ, different class ë¼ë¦¬ëŠ” ë©€ê²Œ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì´ ì•„ë‹ˆë‹¤.
- ìµœëŒ€ 200 epochsë¡œ í•™ìŠµì‹œí‚¤ë‹¤ê°€, **one-shot validation error**ê°€ 20 epochs ë™ì•ˆ ê°ì†Œí•˜ì§€ ì•Šìœ¼ë©´ í•™ìŠµì„ ì¤‘ë‹¨í–ˆë‹¤.
    
    > **one-shot validation error**
    > 
    > = validation setì—ì„œ ëœë¤í•˜ê²Œ ìƒì„±ëœ 320 one-shot learning tasksì—ì„œ ê³„ì‚° 
    {: .prompt-info}

- training setì— **small affine distortions**ë¥¼ ì£¼ì–´ augment í–ˆë‹¤.
    
    ![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2023-02-23-4.png){: style="max-width: 70%"}
    
- ê·¸ ì™¸ ìì„¸í•œ ë‚´ìš©ì€ ë…¼ë¬¸ ì°¸ê³ 

<br>

---

## 3. Experiments

### 3.1 Dataset: Omniglot Dataset

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2023-02-23-5.png){: style="max-width: 70%"}

- handwritten character recognition domainì˜ ë°ì´í„°ì…‹ì´ë‹¤.
- 50ê°€ì§€ ì–¸ì–´ì— ëŒ€í•´ ì´ 1623ê°œì˜ ë¬¸ìë¥¼ í¬í•¨í•˜ê³  ìˆë‹¤.
- 20ëª…ì˜ ë‹¤ë¥¸ ì‚¬ëŒìœ¼ë¡œë¶€í„° ì“°ì˜€ë‹¤. (â†’ ì´ 20*1623ê°œì˜ ë°ì´í„°)
- **êµ¬ë¶„** (â†’ train / validation / test setê³¼ ë³„ê°œë¡œ ì‚¬ìš©ë¨)
    - 40 alphabet background set
        - hyperparameterì™€ feature mappingì„ í•™ìŠµí•˜ëŠ” ëª¨ë¸ì„ í•™ìŠµì‹œí‚¬ ë•Œ ì‚¬ìš©
    - 10 alphabet evaluation set
        - one-shot classification performanceë¥¼ ì¸¡ì •í•  ë•Œ ì‚¬ìš©

<br>

### 3.2 Training Verification Network

![best validation checkpoint & threhsold ì—ì„œì˜ test accuracy](/assets/img/posts/Deep-Learning/Paper-Review/2023-02-23-6.png){: style="max-width: 60%"}
_best validation checkpoint & threhsold ì—ì„œì˜ test accuracy_

- random same / different pairsë¥¼ sampling í•˜ì—¬ ê°ê° 30,000, 90,000, 150,000 training examplesë¡œ ì´ë£¨ì–´ì§„ datasetì„ ë§Œë“¤ì—ˆë‹¤.
    - affine distortionsëŠ” ê° í¬ê¸°ë³„ datasetì— augmented version(8x)ìœ¼ë¡œ ì¶”ê°€í–ˆë‹¤.
- **training ë‹¨ê³„ì—ì„œì˜ performance monitoringì— ì‚¬ìš©í•œ dataset**
    1. verification taskë¥¼ ìœ„í•œ validation set (w/ 10,000 example pairs)
    2. target task(= one-shot recognition)ë¥¼ ìœ„í•œ validation set (w/ 320 one-shot recognition trials)
        
        â†’ termination criterionìœ¼ë¡œ ì‚¬ìš©
        

<br>

### 3.3 One-shot Learning

- siamese networkë¥¼ verification taskì— ì˜ ë™ì‘í•˜ë„ë¡ í•™ìŠµí–ˆìœ¼ë¯€ë¡œ, í•™ìŠµëœ featuresê°€ discriminative potentialì„ ê°€ì¡Œë‹¤ê³  íŒë‹¨í•  ìˆ˜ ìˆë‹¤.
- test ì‹œ ë‹¤ìŒì˜ ì´ë¯¸ì§€ë¥¼ ì…ë ¥í•˜ì—¬, $\mathbf x$ê°€ ì–´ë–¤ classì™€ ê°€ì¥ ë¹„ìŠ·í•œì§€ query í•  ìˆ˜ ìˆë‹¤.
    1. **test image $\mathbf x$ :** $C$ categories ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ê³  ì‹¶ì€ column vector
    2. **some other images $\lbrace\mathbf x_c\rbrace_{c=1}^C$ :** ê° $C$ categoriesì˜ exampleì„ ë‚˜íƒ€ë‚´ëŠ” column vectorsì˜ set
    
    â‡’ **maximum similarity** $C^*= \arg\max_c \mathbf p^{(c)}$
    

#### Evaluate One-shot Learning Performance

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2023-02-23-7.png){: style="max-width: 60%"}

- **20-way within-alphabet classification task**
    - evaluation setì—ì„œ ì‚¬ìš©í•  alphabetì˜ ì¢…ë¥˜ë¥¼ ê³ ë¥¸ë‹¤.
    - í•´ë‹¹ ì¢…ë¥˜ì˜ alphabetì—ì„œ 20 charactersë¥¼ ê³ ë¥¸ë‹¤. (uniformly at random)
    - 20ëª…ì˜ drawers ì¤‘ 2ëª…ì„ ì„ íƒí•˜ì—¬ ê°ê° 20 charactersë¥¼ ê·¸ë¦¬ê²Œ í•œë‹¤.
        - first drawerì˜ charactersëŠ” ê° 1ê°œì˜ **test image** $\mathbf x$
        - second drawerì˜ charactersëŠ” **some other images $\lbrace\mathbf x_c\rbrace_{c=1}^C$**
    - ë‘ ë²ˆ ë°˜ë³µí•˜ì—¬ 40 one-shot learning trialsê°€ ìƒê¸°ë©°, 10 alphabet evaluation setì´ë¯€ë¡œ ì´ 400 one-shot learning trialsê°€ ìƒì„±ëœë‹¤.
- 92%ì˜ test accuracyë¥¼ ë‹¬ì„±í–ˆë‹¤.

#### MNIST One-shot Trial

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2023-02-23-8.png){: style="max-width: 70%"}

- Omniglot datasetìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ì´ MNIST datasetì—ë„ ì¼ë°˜í™”ê°€ ì˜ ë˜ëŠ”ì§€ ì‹¤í—˜í–ˆë‹¤.
    
    **â†’ 10-way one-shot classification task**
    
- ê½¤ë‚˜ ì˜ generalize ëœë‹¤ê³  íŒë‹¨í•  ìˆ˜ ìˆë‹¤.

<br>

---

## 4. Conclusion

- verificationì„ ìœ„í•œ deep convolutional siamese neural networksë¥¼ í•™ìŠµì‹œí‚´ìœ¼ë¡œì¨ one-shot classificationì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ì œì‹œí–ˆë‹¤.
- metric learning approachë¡œ human-level accuracyë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆì—ˆìœ¼ë©°, ë‹¤ë¥¸ ë„ë©”ì¸ì˜ one-shot learning taskì—ë„ ì ìš©ë  ìˆ˜ ìˆë‹¤.
- ë³¸ ë…¼ë¬¸ì—ì„œëŠ” global affine transformì„ ì´ìš©í•œ distortionsë§Œì„ ì¶”ê°€ë¡œ ê³ ë ¤í–ˆìœ¼ë‚˜, individual stroke trajectoriesì— ëŒ€í•œ local affine transformationsë¥¼ ìˆ˜í–‰ í›„ í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ” ë°©ë²•ìœ¼ë¡œ í™•ì¥í•œë‹¤ë©´ variationsì— ë” ì í•©í•œ featureë¥¼ í•™ìŠµí•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.

<br>

![Untitled](/assets/img/posts/Deep-Learning/Paper-Review/2023-02-23-9.png){: style="max-width: 60%"}

<br>

---

## 5. Reference

- <https://jayhey.github.io/deep%20learning/2018/02/06/saimese_network/>
- <https://sorenbouma.github.io/blog/oneshot/>
- <https://tyami.github.io/deep%20learning/Siamese-neural-networks/>
